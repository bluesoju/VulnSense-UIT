{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "\u001b[31m  ERROR: Command errored out with exit status 128:\n",
      "   command: git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-qegfe3wr\n",
      "       cwd: None\n",
      "  Complete output (1 lines):\n",
      "  fatal: unable to access 'https://github.com/pyg-team/pytorch_geometric.git/': Could not resolve host: github.com\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 128: git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-qegfe3wr Check the logs for full command output.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/kien/.local/lib/python3.8/site-packages (4.30.2)\n",
      "Requirement already satisfied: tensorflow_text in /home/kien/.local/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: filelock in /home/kien/.local/lib/python3.8/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in /home/kien/.local/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kien/.local/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow_text) (0.13.0)\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/kien/.local/lib/python3.8/site-packages (from tensorflow_text) (2.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kien/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: fsspec in /home/kien/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kien/.local/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kien/.local/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (4.22.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.13.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.54.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (16.0.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.32.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (23.5.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (45.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.34.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kien/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/kien/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/kien/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/kien/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/kien/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.19.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/kien/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (6.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kien/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kien/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (2.1.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kien/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kien/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kien/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kien/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (3.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/kien/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow_text) (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 08:59:00.368086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kien/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from solcx import compile_standard, install_solc\n",
    "import os\n",
    "from binary_extractor.platforms.ETH.cfg import EthereumCFG\n",
    "from binary_extractor.analysis.graph import CFGGraph\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import cosine_similarity, get_embedding as _get_embedding\n",
    "from tenacity import  stop_after_attempt, wait_random_exponential\n",
    "import openai\n",
    "import jraph\n",
    "import pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dropout, Dense, concatenate\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, Conv1D, concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VulnSense = tf.keras.models.load_model('Model/VulnSense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('Model/M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('Model/M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.load_model('Model/M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVersionPragma(filename):                     # param la path cua contract          \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = file.readlines()\n",
    "    \n",
    "    for line in data:                               # duyet tung dong trong contract do\n",
    "        if 'pragma' in line and 'solidity' in line:                        # neu dong do chua chu \"pragma\"\n",
    "            temp = line.split()                     # chuyen dong do thanh list ['pragma', 'solidity', '^0.4.19;']\n",
    "            if len(temp) == 3 and temp[2][0].isnumeric() == True:       # ['pragma', 'solidity', '0.4.19;']\n",
    "                return temp[2][0:-1]\n",
    "            elif len(temp) == 3 and temp[2][1].isnumeric() == True:       # ['pragma', 'solidity', '^0.4.19;']\n",
    "                return temp[2][1:-1]\n",
    "            elif len(temp) == 3 and temp[2][1].isnumeric() == False:    # ['pragma', 'solidity', '<=0.4.19;']\n",
    "                return temp[2][2:-1]\n",
    "            elif len(temp) > 3 and len(temp[2]) == 1:\n",
    "                return temp[2][-1]\n",
    "            elif len(temp) == 4 and temp[2][1].isnumeric() == True:      # ['pragma', 'solidity', '>0.4.22', '<0.6.0]\n",
    "                return temp[2][1:]\n",
    "            elif len(temp) == 4 and temp[2][1].isnumeric() == False:     # ['pragma', 'solidity', '>=0.4.22', '<0.6.0]\n",
    "                return '0.5.0'\n",
    "    return '0.4.22'\n",
    "\n",
    "def clean_opcode(opcode_str):\n",
    "    # remove hex characters (0x..)\n",
    "    opcode_str = re.sub(r'0x[a-fA-F0-9]+', '', opcode_str)\n",
    "    \n",
    "    # remove newline characters\n",
    "    opcode_str = opcode_str.replace('\\n', ' ')\n",
    "    \n",
    "    # extract only the opcode names\n",
    "    opcodes = re.findall(r'[A-Z]+', opcode_str)\n",
    "    return opcodes\n",
    "\n",
    "def get_bytecode(regex, bytecode):\n",
    "    cc = bytecode.split(regex)\n",
    "    bytecode = ''.join(cc)\n",
    "    match = re.findall(r\"__.{1,50}_\", bytecode)\n",
    "    if len(match) != 0:\n",
    "        bytecode = get_bytecode(match[0], bytecode)\n",
    "        return bytecode\n",
    "    else:\n",
    "        return bytecode\n",
    "\n",
    "def return_source_code(file_path):\n",
    "    with open(file_path,\"r\", encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def return_bytecode_opcode(file_path):\n",
    "    with open (file_path, \"r\", encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    version = getVersionPragma(file_path)\n",
    "    print(version)\n",
    "    try:\n",
    "        install_solc(version)\n",
    "    except:\n",
    "        version = '0.4.11'\n",
    "        install_solc(version)\n",
    "    try:\n",
    "        compiled_sol = compile_standard(\n",
    "            {\n",
    "                \"language\": \"Solidity\",\n",
    "                \"sources\": {'cc': {\"content\": content}},\n",
    "                \"settings\": {\n",
    "                    \"outputSelection\": {\n",
    "                        \"*\": {\n",
    "                            \"*\": [\"evm.bytecode.opcodes\", \"metadata\", \"evm.bytecode.sourceMap\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            solc_version=version,\n",
    "        )\n",
    "    except:\n",
    "        compiled_sol = compile_standard(\n",
    "            {\n",
    "                \"language\": \"Solidity\",\n",
    "                \"sources\": {'cc': {\"content\": content}},\n",
    "                \"settings\": {\n",
    "                    \"outputSelection\": {\n",
    "                        \"*\": {\n",
    "                            \"*\": [\"evm.bytecode.opcodes\", \"metadata\", \"evm.bytecode.sourceMap\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            solc_version='0.4.24',\n",
    "        )\n",
    "\n",
    "    contracts_name = compiled_sol[\"contracts\"]['cc'].keys()\n",
    "    list_opcode = []\n",
    "    list_bytecode = []\n",
    "    for contract in contracts_name:\n",
    "        bytecode = compiled_sol[\"contracts\"][\"cc\"][contract][\"evm\"][\"bytecode\"][\"object\"]\n",
    "        opcode = compiled_sol[\"contracts\"][\"cc\"][contract][\"evm\"][\"bytecode\"][\"opcodes\"]\n",
    "        \n",
    "        \n",
    "        match = re.findall(r\"__.{1,50}_\", bytecode)\n",
    "        if len(match) != 0:\n",
    "            bytecode = get_bytecode(match[0], bytecode)\n",
    "\n",
    "        list_bytecode.append(bytecode)\n",
    "        list_opcode.append(opcode)\n",
    "    \n",
    "    final_bytecode = ''.join(list_bytecode)\n",
    "    final_opcode = ''.join(list_opcode)\n",
    "    final_opcode = clean_opcode(final_opcode)\n",
    "    final_opcode = ' '.join(final_opcode)\n",
    "    return final_bytecode, final_opcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comment(inputFile):\n",
    "    with open(inputFile, 'r', encoding=\"utf-8\") as f:\n",
    "        source_code = f.read()\n",
    "    #fdw = open(outputFile, 'w', encoding=\"utf-8\")\n",
    "    \n",
    "    source_code = re.sub(r\"//\\*.*\", \"\", source_code)\n",
    "    source_code = re.sub(r\"#.*\", \"\", source_code)\n",
    "    # Remove multi-line comments\n",
    "    source_code = re.sub(r\"/\\*.*?\\*/\", \"\", source_code, flags=re.DOTALL)\n",
    "    source_code = re.sub(r\"\\\"\\\"\\\".*?\\\"\\\"\\\"/\", \"\", source_code, flags=re.DOTALL)\n",
    "    \n",
    "    source_code = re.sub(r\"//.*\", \"\", source_code)\n",
    "\n",
    "    # Remove redundant spaces and tabs\n",
    "    source_code = re.sub(r\"[\\t ]+\", \" \", source_code)\n",
    "\n",
    "    # Remove empty lines\n",
    "    source_code = re.sub(r\"^\\s*\\n\", \"\", source_code, flags=re.MULTILINE)\n",
    "    return source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytecode_to_cfg(bytecode_hex):\n",
    "    # create the CFG\n",
    "    cfg = EthereumCFG(bytecode_hex)\n",
    "    graph = CFGGraph(cfg)\n",
    "    graph.view()\n",
    "    \n",
    "    with open('/home/kien/Desktop/VulnSense/graph.cfg.gv', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    nodes = []\n",
    "    edges = []\n",
    "    \n",
    "    flag = 0\n",
    "    for line in lines:\n",
    "        if \"block\" in line and flag == 0:\n",
    "            nodes.append(re.sub(r'\\\\l', r' ', line).strip())\n",
    "        if \"block\" in line and flag != 0:\n",
    "            edges.append(line.strip())\n",
    "        if \"}\" in line:\n",
    "            flag += 1\n",
    "            continue\n",
    "        \n",
    "    # s = ''\n",
    "    # final_nodes = []\n",
    "    # i = 0\n",
    "    # for line in nodes:\n",
    "    #     list = line.split(\" \")\n",
    "    #     for i in list:\n",
    "    #         if i[0:2] == \"0x\":\n",
    "    #             s += i\n",
    "    #         if i[0:1].isupper() != 0:\n",
    "    #             s += i\n",
    "    #         s += ' '\n",
    "    #         s = s.replace(\"  \", \" \")\n",
    "    #     final_nodes.append(s)\n",
    "        \n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "get_embedding = _get_embedding.retry_with(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(10))\n",
    "\n",
    "\n",
    "FEATURE_NUM = 1536\n",
    "EDGE_FEATURE_NUM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_dict(edges: str) -> List[dict]:\n",
    "    adj_dict = {}\n",
    "    edge_id = 0\n",
    "    edge_id_dict = {}\n",
    "    edge_type = {\"red\": 0, \"green\": 1, \"blue\": 2, \"cyan\": 3}\n",
    "    for line in edges:\n",
    "        if \"block\" in line:\n",
    "            # Split the line into block_id and block_dest_id\n",
    "            block_id, block_dest_id = line.split(\" -> \")\n",
    "\n",
    "            # Cleaning to get block_id, block_dest_id, edge_label\n",
    "            block_id = block_id.strip()\n",
    "            block_dest_id, edge_label = block_dest_id.split(\"[color=\")\n",
    "            block_dest_id = block_dest_id.strip()\n",
    "            edge_label = edge_label.strip()[:-1]\n",
    "\n",
    "\n",
    "            if block_id not in adj_dict:\n",
    "                adj_dict[block_id] = []\n",
    "            adj_dict[block_id].append((block_dest_id, edge_type[edge_label]))\n",
    "    return adj_dict\n",
    "\n",
    "def get_x_dict(nodes: str) -> List[dict]:\n",
    "    X_dict = {}\n",
    "    for line in nodes:\n",
    "        if \"block\" in line:\n",
    "            block_id, label = line.split(\" [label=\")\n",
    "            block_id = block_id.strip()\n",
    "            label = label.strip().strip('\"')\n",
    "            label = label[:-2].strip()\n",
    "            X_dict[block_id] = label\n",
    "    return X_dict\n",
    "\n",
    "def encoder(code: str) -> np.ndarray:\n",
    "    text = \"This is a block of EVM bytecode: \" + code\n",
    "    model_id = \"text-embedding-ada-002\"\n",
    "    emb = openai.Embedding.create(input=[text], model=model_id)['data'][0]['embedding']\n",
    "    emb_np = np.array(emb)\n",
    "    return emb_np\n",
    "\n",
    "def make_jraph_dataset(nodes, edges):\n",
    "    x_dict = get_x_dict(nodes)\n",
    "    adj_dict = get_adj_dict(edges)\n",
    "    COUNT = 0\n",
    "    for key in adj_dict.keys():\n",
    "            if key not in x_dict.keys():\n",
    "                raise Exception(f\"Key {key} not in x_dict\")\n",
    "        \n",
    "    blk_id_to_index = {blk_id: i for i, (blk_id, _) in enumerate(x_dict.items())}\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    senders = []\n",
    "    receivers = []\n",
    "    dataset = []\n",
    "\n",
    "    # Convert dicts to jraph representation\n",
    "    for i, (blk,code) in enumerate(x_dict.items()):\n",
    "        COUNT = COUNT + 1\n",
    "        t = time.localtime()\n",
    "        current_time = time.strftime(\"%S\", t)\n",
    "        if current_time == 0:\n",
    "            COUNT = 0\n",
    "        if COUNT >= 55 and int(current_time) < 59:\n",
    "            time.sleep(65 - int(current_time))\n",
    "            COUNT = 0\n",
    "            print(f\"Waiting for {65 - int(current_time)}\")\n",
    "        nodes.append(encoder(code))\n",
    "        if blk in adj_dict:\n",
    "            for (dest, edge_type) in adj_dict[blk]:\n",
    "                edge_one_hot = np.zeros((EDGE_FEATURE_NUM,))\n",
    "                edge_one_hot[edge_type] = 1\n",
    "                edges.append(edge_one_hot)\n",
    "                senders.append(blk_id_to_index[blk])\n",
    "                receivers.append(blk_id_to_index[dest])\n",
    "    \n",
    "    # Convert to jraph\n",
    "    graph = jraph.GraphsTuple(\n",
    "                                n_node=np.array([len(nodes)]),\n",
    "                                n_edge=np.array([len(edges)]),\n",
    "                                nodes=np.array(nodes), \n",
    "                                edges=np.array(edges), \n",
    "                                senders=np.array(senders), \n",
    "                                receivers=np.array(receivers), \n",
    "                                globals=np.array([1]),\n",
    "                            )\n",
    "    target = [1]\n",
    "    dataset.append({\"input_graph\": graph, \"target\": target})\n",
    "    # with open('graph_test_dataset.pkl', 'wb') as f:\n",
    "    #     pickle.dump(dataset, f)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_source_code_2_file(address):\n",
    "#     try:\n",
    "#       r = requests.get(f'https://api.etherscan.io/api?module=contract&action=getsourcecode&address={address}&apikey=II5M5BPF2DJNW5Y3WZKZJV6N7HCSUJ4UNZ')\n",
    "#       cc = r.text\n",
    "#       res = json.loads(cc)\n",
    "#       source = res['result'][0]['SourceCode']\n",
    "  \n",
    "#       with open(f'{address}.sol', 'w', encoding='utf-8') as f:\n",
    "#           f.write(source)\n",
    "#     except:\n",
    "#       pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option == 0:\n",
    "    address = 'test'\n",
    "else:\n",
    "    address = input()\n",
    "    # get_source_code_2_file(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code = remove_comment(f'{address}.sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.24\n"
     ]
    }
   ],
   "source": [
    "bytecode, opcode = return_bytecode_opcode(f'{address}.sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:binary_extractor.arch.evm.cfg:function signatures collision: ['decimals()', 'available_assert_time(uint16,uint64)']\n",
      "WARNING:binary_extractor.arch.evm.cfg:function signatures collision: ['collate_propagate_storage(bytes16)', 'burn(uint256)']\n",
      "WARNING:binary_extractor.arch.evm.cfg:function signatures collision: ['ideal_warn_timed(uint256,uint128)', 'owner()']\n",
      "WARNING:binary_extractor.arch.evm.cfg:function signatures collision: ['symbol()', 'link_classic_internal(uint64,int64)']\n",
      "WARNING:binary_extractor.arch.evm.emulator:[X] Loop detected, skipping JUMPI 0x128a\n",
      "WARNING:binary_extractor.arch.evm.emulator:[X] push_instr.ssa %735 = #0x128A\n",
      "WARNING:binary_extractor.arch.evm.emulator:[X] Loop detected, skipping JUMPI 0x93e\n",
      "WARNING:binary_extractor.arch.evm.emulator:[X] push_instr.ssa %C1A = #0x93E\n"
     ]
    }
   ],
   "source": [
    "nodes, edges = bytecode_to_cfg(bytecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fec00bcca00>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /v1/embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 35\n",
      "Waiting for 32\n",
      "Waiting for 17\n",
      "Waiting for 31\n"
     ]
    }
   ],
   "source": [
    "dataset = make_jraph_dataset(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = torch.tensor(dataset[0]['input_graph'][0], dtype=torch.float)\n",
    "edges = torch.tensor(dataset[0]['input_graph'][1], dtype=torch.float)\n",
    "senders = torch.tensor(dataset[0]['input_graph'][3], dtype=torch.long)\n",
    "receivers = torch.tensor(dataset[0]['input_graph'][2], dtype=torch.long)\n",
    "label = torch.tensor([0], dtype=torch.long)\n",
    "edge_index = torch.stack([senders, receivers], dim=0)\n",
    "data = Data(edge_index=edge_index, x=nodes, edge_attr=edges, y=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_list, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(1536, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv4 = GCNConv(128, 64)\n",
    "        self.lin = Linear(hidden_channels, 3)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv4(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "model = GCN(hidden_channels=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      for data in loader:  # Iterate in batches over the training dataset.\n",
    "            out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "            return(out.detach().tolist()[0])\n",
    "gnn_input = train()\n",
    "for i in range(len(gnn_input)):\n",
    "    gnn_input[i] = gnn_input[i]\n",
    "gnn_input = np.array([[gnn_input]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['opcode', 'source_code']\n",
    "row = [[opcode, source_code]]\n",
    "df = pd.DataFrame(row, columns=header)\n",
    "VOCAB_OP_SIZE = df['opcode'].nunique()\n",
    "MAX_OPCODE_LENGTH = 200\n",
    "EMBEDDING_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo tokenizer\n",
    "tokenizer = Tokenizer(num_words=1411)\n",
    "\n",
    "# Fit tokenizer với các opcode\n",
    "tokenizer.fit_on_texts(df['opcode'])\n",
    "\n",
    "# Chuyển đổi các opcode thành các sequence\n",
    "sequences = tokenizer.texts_to_sequences(df['opcode'])\n",
    "\n",
    "# Padding các sequence để có độ dài bằng nhau\n",
    "opcode_matrix = pad_sequences(sequences, maxlen=MAX_OPCODE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_vulnsense = VulnSense.predict([df['source_code'], opcode_matrix, gnn_input])\n",
    "y_pred_classes_vulnsense = np.argmax(y_pred_vulnsense, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_m1 = model1.predict([df['source_code'], opcode_matrix])\n",
    "y_pred_classes_m1 = np.argmax(y_pred_m1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_m2 = model2.predict([df['source_code'], gnn_input])\n",
    "y_pred_classes_m2 = np.argmax(y_pred_m2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_m3 = model3.predict([opcode_matrix, gnn_input])\n",
    "y_pred_classes_m3 = np.argmax(y_pred_m3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1: Clean\n",
      "M2: Clean\n",
      "M3: Clean\n",
      "VulnSense: Clean\n"
     ]
    }
   ],
   "source": [
    "vuln_dict = {0: 'Arithmetic', 1: 'Clean', 2: 'Reentrancy'}\n",
    "print('M1:', vuln_dict[y_pred_classes_m1[0]])\n",
    "print('M2:', vuln_dict[y_pred_classes_m2[0]])\n",
    "print('M3:', vuln_dict[y_pred_classes_m3[0]])\n",
    "print('VulnSense:', vuln_dict[y_pred_classes_vulnsense[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
